{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2Fsifs0F5Tu/JmEbfNZ/v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elsaimo/4106_Final_project/blob/main/SelenaNahraFinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Dataset & Preprocessing**"
      ],
      "metadata": {
        "id": "pUpuiWc1Vy-8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "KoAMNLX7Sw_c",
        "outputId": "9f12010e-076b-4594-8162-d60dfadb476c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 920 entries, 0 to 919\n",
            "Data columns (total 16 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   id        920 non-null    int64  \n",
            " 1   age       920 non-null    int64  \n",
            " 2   sex       920 non-null    object \n",
            " 3   dataset   920 non-null    object \n",
            " 4   cp        920 non-null    object \n",
            " 5   trestbps  861 non-null    float64\n",
            " 6   chol      890 non-null    float64\n",
            " 7   fbs       830 non-null    object \n",
            " 8   restecg   918 non-null    object \n",
            " 9   thalch    865 non-null    float64\n",
            " 10  exang     865 non-null    object \n",
            " 11  oldpeak   858 non-null    float64\n",
            " 12  slope     611 non-null    object \n",
            " 13  ca        309 non-null    float64\n",
            " 14  thal      434 non-null    object \n",
            " 15  num       920 non-null    int64  \n",
            "dtypes: float64(5), int64(3), object(8)\n",
            "memory usage: 115.1+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
              "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
              "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
              "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
              "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
              "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
              "\n",
              "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
              "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
              "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
              "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
              "3          normal   187.0  False      3.5  downsloping  0.0   \n",
              "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
              "\n",
              "                thal  num  \n",
              "0       fixed defect    0  \n",
              "1             normal    2  \n",
              "2  reversable defect    1  \n",
              "3             normal    0  \n",
              "4             normal    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bec07389-054c-42d5-8c7d-17f9be0e1e66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>dataset</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalch</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>63</td>\n",
              "      <td>Male</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>typical angina</td>\n",
              "      <td>145.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>True</td>\n",
              "      <td>lv hypertrophy</td>\n",
              "      <td>150.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2.3</td>\n",
              "      <td>downsloping</td>\n",
              "      <td>0.0</td>\n",
              "      <td>fixed defect</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>67</td>\n",
              "      <td>Male</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>asymptomatic</td>\n",
              "      <td>160.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>False</td>\n",
              "      <td>lv hypertrophy</td>\n",
              "      <td>108.0</td>\n",
              "      <td>True</td>\n",
              "      <td>1.5</td>\n",
              "      <td>flat</td>\n",
              "      <td>3.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>67</td>\n",
              "      <td>Male</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>asymptomatic</td>\n",
              "      <td>120.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>False</td>\n",
              "      <td>lv hypertrophy</td>\n",
              "      <td>129.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2.6</td>\n",
              "      <td>flat</td>\n",
              "      <td>2.0</td>\n",
              "      <td>reversable defect</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>Male</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>non-anginal</td>\n",
              "      <td>130.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>False</td>\n",
              "      <td>normal</td>\n",
              "      <td>187.0</td>\n",
              "      <td>False</td>\n",
              "      <td>3.5</td>\n",
              "      <td>downsloping</td>\n",
              "      <td>0.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>41</td>\n",
              "      <td>Female</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>atypical angina</td>\n",
              "      <td>130.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>False</td>\n",
              "      <td>lv hypertrophy</td>\n",
              "      <td>172.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1.4</td>\n",
              "      <td>upsloping</td>\n",
              "      <td>0.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bec07389-054c-42d5-8c7d-17f9be0e1e66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bec07389-054c-42d5-8c7d-17f9be0e1e66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bec07389-054c-42d5-8c7d-17f9be0e1e66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fae72a49-baff-4a39-a60c-aa9902494af6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fae72a49-baff-4a39-a60c-aa9902494af6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fae72a49-baff-4a39-a60c-aa9902494af6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 920,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 265,\n        \"min\": 1,\n        \"max\": 920,\n        \"num_unique_values\": 920,\n        \"samples\": [\n          320,\n          378,\n          539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 28,\n        \"max\": 77,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          64,\n          74,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Hungary\",\n          \"VA Long Beach\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"asymptomatic\",\n          \"atypical angina\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.066069518587476,\n        \"min\": 0.0,\n        \"max\": 200.0,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          145.0,\n          172.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 110.7808103532305,\n        \"min\": 0.0,\n        \"max\": 603.0,\n        \"num_unique_values\": 217,\n        \"samples\": [\n          384.0,\n          333.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"lv hypertrophy\",\n          \"normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.926276492797594,\n        \"min\": 60.0,\n        \"max\": 202.0,\n        \"num_unique_values\": 119,\n        \"samples\": [\n          185.0,\n          134.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0912262483465298,\n        \"min\": -2.6,\n        \"max\": 6.2,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          2.4,\n          -1.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"downsloping\",\n          \"flat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.935653012559987,\n        \"min\": 0.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"fixed defect\",\n          \"normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"heart_disease_uci.csv\")\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove irrelevant columns\n",
        "df = df.drop(columns=['id','dataset'])\n",
        "\n",
        "#remove columns with null values\n",
        "df.isnull().values.any()\n",
        "df = df.dropna()\n",
        "\n",
        "df.info()\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IJGGRBFTDNk",
        "outputId": "ca141bc4-8775-472f-aca8-a1c31649a1b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 299 entries, 0 to 748\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       299 non-null    int64  \n",
            " 1   sex       299 non-null    object \n",
            " 2   cp        299 non-null    object \n",
            " 3   trestbps  299 non-null    float64\n",
            " 4   chol      299 non-null    float64\n",
            " 5   fbs       299 non-null    object \n",
            " 6   restecg   299 non-null    object \n",
            " 7   thalch    299 non-null    float64\n",
            " 8   exang     299 non-null    object \n",
            " 9   oldpeak   299 non-null    float64\n",
            " 10  slope     299 non-null    object \n",
            " 11  ca        299 non-null    float64\n",
            " 12  thal      299 non-null    object \n",
            " 13  num       299 non-null    int64  \n",
            "dtypes: float64(5), int64(2), object(7)\n",
            "memory usage: 35.0+ KB\n",
            "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalch',\n",
            "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encode Male = 0 & Female = 1\n",
        "df['sex'] = df['sex'].map({'Female': 1, 'Male': 0})\n",
        "\n",
        "#encode cp, restecg, slope, thal\n",
        "onehot_encoder = ce.OneHotEncoder(cols=['cp', 'restecg', 'slope', 'thal'])\n",
        "df = onehot_encoder.fit_transform(df)\n",
        "\n",
        "#True = 1, False = 0\n",
        "df[['fbs', 'exang']] = df[['fbs', 'exang']].astype(int)\n",
        "\n",
        "#scale age, trestbps, chol, thalach, oldpeak, ca\n",
        "scaler = StandardScaler()\n",
        "columns_to_scale = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak','ca']\n",
        "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "EQ4m6-cMUCqo",
        "outputId": "0db08061-4bea-4dbe-b123-bee529b21b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  sex  cp_1  cp_2  cp_3  cp_4  trestbps      chol  fbs  restecg_1  \\\n",
              "0  0.940446    0     1     0     0     0  0.749760 -0.262867    1          1   \n",
              "1  1.384143    0     0     1     0     0  1.596354  0.747722    0          1   \n",
              "2  1.384143    0     0     1     0     0 -0.661231 -0.339138    0          1   \n",
              "3 -1.943588    0     0     0     1     0 -0.096835  0.061285    0          0   \n",
              "4 -1.499891    1     0     0     0     1 -0.096835 -0.815830    0          1   \n",
              "\n",
              "   ...  exang   oldpeak  slope_1  slope_2  slope_3        ca  thal_1  thal_2  \\\n",
              "0  ...      0  1.069475        1        0        0 -0.718306       1       0   \n",
              "1  ...      1  0.380309        0        1        0  2.487269       0       1   \n",
              "2  ...      1  1.327912        0        1        0  1.418744       0       0   \n",
              "3  ...      0  2.103224        1        0        0 -0.718306       0       1   \n",
              "4  ...      0  0.294163        0        0        1 -0.718306       0       1   \n",
              "\n",
              "   thal_3  num  \n",
              "0       0    0  \n",
              "1       0    2  \n",
              "2       1    1  \n",
              "3       0    0  \n",
              "4       0    0  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdeafdeb-4341-4ae2-af7f-f11c55414a58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>cp_4</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>...</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope_1</th>\n",
              "      <th>slope_2</th>\n",
              "      <th>slope_3</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.940446</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.749760</td>\n",
              "      <td>-0.262867</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.069475</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.718306</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.384143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.596354</td>\n",
              "      <td>0.747722</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.380309</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.487269</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.384143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.661231</td>\n",
              "      <td>-0.339138</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.327912</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.418744</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.943588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.096835</td>\n",
              "      <td>0.061285</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2.103224</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.718306</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.499891</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.096835</td>\n",
              "      <td>-0.815830</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.294163</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.718306</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdeafdeb-4341-4ae2-af7f-f11c55414a58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cdeafdeb-4341-4ae2-af7f-f11c55414a58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cdeafdeb-4341-4ae2-af7f-f11c55414a58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-81ad3b25-a5dc-4cef-8074-7e1f27698ed9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81ad3b25-a5dc-4cef-8074-7e1f27698ed9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-81ad3b25-a5dc-4cef-8074-7e1f27698ed9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_distribution = df['num'].value_counts()\n",
        "sorted_distribution = class_distribution.sort_index()\n",
        "print(sorted_distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmHRQYUNU3lK",
        "outputId": "9f68bd20-2e5a-4801-be9b-9fc7dcc65604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num\n",
            "0    160\n",
            "1     56\n",
            "2     35\n",
            "3     35\n",
            "4     13\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "X = df.drop(columns=[\"num\"])\n",
        "y = df[\"num\"]\n",
        "\n",
        "print(\"Shape of X\", X.shape)\n",
        "print(\"Shape of y\", y.shape)\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(y_resampled.value_counts())\n",
        "\n",
        "X = X_resampled.values\n",
        "y = y_resampled.values.reshape(-1, 1)\n",
        "\n",
        "print(\"Shape of X\", X.shape)\n",
        "print(\"Shape of y\", y.shape)\n",
        "\n",
        "\n",
        "# 80-20 Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print('Shape of X_train:', X_train.shape)\n",
        "print('Shape of y_train:', y_train.shape)\n",
        "print('Shape of X_val:', X_val.shape)\n",
        "print('Shape of y_val:', y_val.shape)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long).squeeze()\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long).squeeze()\n",
        "\n",
        "# Reshape X_val to include a batch dimension\n",
        "X_val = X_val.unsqueeze(1)\n",
        "X_train = X_train.unsqueeze(1)\n",
        "\n",
        "print('Shape of X_train:', X_train.shape)\n",
        "print('Shape of y_train:', y_train.shape)\n",
        "print('Shape of X_val:', X_val.shape)\n",
        "print('Shape of y_val:', y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaTVC6BEaYzp",
        "outputId": "bfb0e66c-9c77-4d4a-c7f2-a58e7903a5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X (299, 22)\n",
            "Shape of y (299,)\n",
            "num\n",
            "0    160\n",
            "2    160\n",
            "1    160\n",
            "3    160\n",
            "4    160\n",
            "Name: count, dtype: int64\n",
            "Shape of X (800, 22)\n",
            "Shape of y (800, 1)\n",
            "Shape of X_train: (640, 22)\n",
            "Shape of y_train: (640, 1)\n",
            "Shape of X_val: (160, 22)\n",
            "Shape of y_val: (160, 1)\n",
            "Shape of X_train: torch.Size([640, 1, 22])\n",
            "Shape of y_train: torch.Size([640])\n",
            "Shape of X_val: torch.Size([160, 1, 22])\n",
            "Shape of y_val: torch.Size([160])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline Model**"
      ],
      "metadata": {
        "id": "1EjIpkkFE5lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKsjhTlDCJ55",
        "outputId": "6e11ca6d-71b0-4f33-fced-5a1d8e36aa86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.8883615732192993, Validation Loss: 1.0464003086090088, Validation Accuracy: 0.59375\n",
            "Epoch 20, Loss: 0.660047709941864, Validation Loss: 0.8754264712333679, Validation Accuracy: 0.6875\n",
            "Epoch 30, Loss: 0.4255477786064148, Validation Loss: 0.7595152854919434, Validation Accuracy: 0.762499988079071\n",
            "Epoch 40, Loss: 0.2452319711446762, Validation Loss: 0.6429844498634338, Validation Accuracy: 0.78125\n",
            "Epoch 50, Loss: 0.11846320331096649, Validation Loss: 0.6140075325965881, Validation Accuracy: 0.824999988079071\n",
            "Epoch 60, Loss: 0.04601437970995903, Validation Loss: 0.6578974723815918, Validation Accuracy: 0.84375\n",
            "Epoch 70, Loss: 0.02187536470592022, Validation Loss: 0.714775025844574, Validation Accuracy: 0.8500000238418579\n",
            "Epoch 80, Loss: 0.012836094945669174, Validation Loss: 0.762371301651001, Validation Accuracy: 0.84375\n",
            "Epoch 90, Loss: 0.00846178736537695, Validation Loss: 0.800655722618103, Validation Accuracy: 0.8500000238418579\n",
            "Epoch 100, Loss: 0.0060032750479876995, Validation Loss: 0.8320589065551758, Validation Accuracy: 0.8500000238418579\n",
            "Total training time: 94.76 seconds\n",
            "Accuracy on test set: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decreased Batch Size**"
      ],
      "metadata": {
        "id": "cAtH42NiSQkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPpvwfr7S9Tl",
        "outputId": "e87e5148-ecdf-45cd-cb44-4a60af0708e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.6698464751243591, Validation Loss: 0.9519360661506653, Validation Accuracy: 0.6187499761581421\n",
            "Epoch 20, Loss: 0.33123281598091125, Validation Loss: 0.7542014718055725, Validation Accuracy: 0.768750011920929\n",
            "Epoch 30, Loss: 0.13529735803604126, Validation Loss: 0.635811984539032, Validation Accuracy: 0.7749999761581421\n",
            "Epoch 40, Loss: 0.051359955221414566, Validation Loss: 0.6470862627029419, Validation Accuracy: 0.8125\n",
            "Epoch 50, Loss: 0.019306611269712448, Validation Loss: 0.7269688248634338, Validation Accuracy: 0.8374999761581421\n",
            "Epoch 60, Loss: 0.009878827258944511, Validation Loss: 0.7987085580825806, Validation Accuracy: 0.84375\n",
            "Epoch 70, Loss: 0.005991948302835226, Validation Loss: 0.8524749875068665, Validation Accuracy: 0.8374999761581421\n",
            "Epoch 80, Loss: 0.003986150957643986, Validation Loss: 0.894262969493866, Validation Accuracy: 0.8374999761581421\n",
            "Epoch 90, Loss: 0.0028186459094285965, Validation Loss: 0.9281314611434937, Validation Accuracy: 0.8374999761581421\n",
            "Epoch 100, Loss: 0.0020870366133749485, Validation Loss: 0.9570955038070679, Validation Accuracy: 0.8374999761581421\n",
            "Total training time: 125.31 seconds\n",
            "Accuracy on test set: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Increased Batch Size**"
      ],
      "metadata": {
        "id": "6jFOuhT7TAR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP6jnnWWTDX1",
        "outputId": "b0b6ab3e-06ae-469d-f222-fc4c8a776842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.0411356687545776, Validation Loss: 1.089917540550232, Validation Accuracy: 0.59375\n",
            "Epoch 20, Loss: 0.7792952060699463, Validation Loss: 1.0334542989730835, Validation Accuracy: 0.6000000238418579\n",
            "Epoch 30, Loss: 0.6215815544128418, Validation Loss: 0.8993126749992371, Validation Accuracy: 0.675000011920929\n",
            "Epoch 40, Loss: 0.4625377357006073, Validation Loss: 0.7992598414421082, Validation Accuracy: 0.75\n",
            "Epoch 50, Loss: 0.3040144145488739, Validation Loss: 0.6933980584144592, Validation Accuracy: 0.78125\n",
            "Epoch 60, Loss: 0.1810833066701889, Validation Loss: 0.6412329077720642, Validation Accuracy: 0.8187500238418579\n",
            "Epoch 70, Loss: 0.10365495085716248, Validation Loss: 0.6491473913192749, Validation Accuracy: 0.84375\n",
            "Epoch 80, Loss: 0.05620427429676056, Validation Loss: 0.6897827982902527, Validation Accuracy: 0.856249988079071\n",
            "Epoch 90, Loss: 0.03166572004556656, Validation Loss: 0.7407079935073853, Validation Accuracy: 0.856249988079071\n",
            "Epoch 100, Loss: 0.020012537017464638, Validation Loss: 0.7876860499382019, Validation Accuracy: 0.8500000238418579\n",
            "Total training time: 70.53 seconds\n",
            "Accuracy on test set: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decreased Learning Rate**"
      ],
      "metadata": {
        "id": "LwpWmEf1T3Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2jh2ZdET8JX",
        "outputId": "ee83f359-ee23-408d-ac66-8689efb07928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.39342838525772095, Validation Loss: 0.7981399297714233, Validation Accuracy: 0.768750011920929\n",
            "Epoch 20, Loss: 0.03792089596390724, Validation Loss: 0.6940580606460571, Validation Accuracy: 0.831250011920929\n",
            "Epoch 30, Loss: 0.0022427549120038748, Validation Loss: 0.9339679479598999, Validation Accuracy: 0.831250011920929\n",
            "Epoch 40, Loss: 0.000865674577653408, Validation Loss: 0.9459837079048157, Validation Accuracy: 0.8500000238418579\n",
            "Epoch 50, Loss: 0.0005832788883708417, Validation Loss: 0.9796146154403687, Validation Accuracy: 0.8500000238418579\n",
            "Epoch 60, Loss: 0.0004298501298762858, Validation Loss: 1.0062050819396973, Validation Accuracy: 0.84375\n",
            "Epoch 70, Loss: 0.00033346208510920405, Validation Loss: 1.0288046598434448, Validation Accuracy: 0.84375\n",
            "Epoch 80, Loss: 0.0002677537268027663, Validation Loss: 1.0484201908111572, Validation Accuracy: 0.84375\n",
            "Epoch 90, Loss: 0.000220488291233778, Validation Loss: 1.0658385753631592, Validation Accuracy: 0.84375\n",
            "Epoch 100, Loss: 0.00018512117094360292, Validation Loss: 1.0814838409423828, Validation Accuracy: 0.84375\n",
            "Total training time: 51.82 seconds\n",
            "Accuracy on test set: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Increased Learning Rate**"
      ],
      "metadata": {
        "id": "GV0JzCq3T8Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ELuga9T_K5",
        "outputId": "c4747197-575e-42d7-e692-659ba3d88b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.576312780380249, Validation Loss: 1.580938696861267, Validation Accuracy: 0.375\n",
            "Epoch 20, Loss: 1.441702127456665, Validation Loss: 1.4705885648727417, Validation Accuracy: 0.518750011920929\n",
            "Epoch 30, Loss: 1.2560884952545166, Validation Loss: 1.3325674533843994, Validation Accuracy: 0.5062500238418579\n",
            "Epoch 40, Loss: 1.1806203126907349, Validation Loss: 1.262160062789917, Validation Accuracy: 0.518750011920929\n",
            "Epoch 50, Loss: 1.1267364025115967, Validation Loss: 1.2023589611053467, Validation Accuracy: 0.550000011920929\n",
            "Epoch 60, Loss: 1.0811747312545776, Validation Loss: 1.1505844593048096, Validation Accuracy: 0.5625\n",
            "Epoch 70, Loss: 1.0430935621261597, Validation Loss: 1.116891860961914, Validation Accuracy: 0.59375\n",
            "Epoch 80, Loss: 1.0080974102020264, Validation Loss: 1.09671151638031, Validation Accuracy: 0.606249988079071\n",
            "Epoch 90, Loss: 0.974942684173584, Validation Loss: 1.0833690166473389, Validation Accuracy: 0.6000000238418579\n",
            "Epoch 100, Loss: 0.9434323310852051, Validation Loss: 1.0730994939804077, Validation Accuracy: 0.612500011920929\n",
            "Total training time: 48.69 seconds\n",
            "Accuracy on test set: 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decreased Hidden Size**"
      ],
      "metadata": {
        "id": "P-yY1JRuV9R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "7UTiMAVjV83p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76142b9a-097e-49dd-fb3d-c5d0e5ab9df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.035675287246704, Validation Loss: 1.0890798568725586, Validation Accuracy: 0.59375\n",
            "Epoch 20, Loss: 0.7721087336540222, Validation Loss: 1.0199354887008667, Validation Accuracy: 0.612500011920929\n",
            "Epoch 30, Loss: 0.6134992837905884, Validation Loss: 0.9003657102584839, Validation Accuracy: 0.668749988079071\n",
            "Epoch 40, Loss: 0.45651909708976746, Validation Loss: 0.8126593828201294, Validation Accuracy: 0.7562500238418579\n",
            "Epoch 50, Loss: 0.304522305727005, Validation Loss: 0.7130411267280579, Validation Accuracy: 0.7749999761581421\n",
            "Epoch 60, Loss: 0.18508930504322052, Validation Loss: 0.6526480317115784, Validation Accuracy: 0.793749988079071\n",
            "Epoch 70, Loss: 0.10667737573385239, Validation Loss: 0.6481569409370422, Validation Accuracy: 0.824999988079071\n",
            "Epoch 80, Loss: 0.05736270919442177, Validation Loss: 0.6814027428627014, Validation Accuracy: 0.831250011920929\n",
            "Epoch 90, Loss: 0.03183982893824577, Validation Loss: 0.7308245897293091, Validation Accuracy: 0.84375\n",
            "Epoch 100, Loss: 0.020072732120752335, Validation Loss: 0.7788512110710144, Validation Accuracy: 0.84375\n",
            "Total training time: 72.40 seconds\n",
            "Accuracy on test set: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Increased Hidden Size**"
      ],
      "metadata": {
        "id": "A5KRv5T9WUP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "Vf80bXaTWY9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cfd0c53-ec8a-447a-d8e5-59e2b9bd8f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.9242163896560669, Validation Loss: 1.0806138515472412, Validation Accuracy: 0.574999988079071\n",
            "Epoch 20, Loss: 0.6883195638656616, Validation Loss: 0.9516040086746216, Validation Accuracy: 0.65625\n",
            "Epoch 30, Loss: 0.488862544298172, Validation Loss: 0.8458717465400696, Validation Accuracy: 0.7437499761581421\n",
            "Epoch 40, Loss: 0.2950717508792877, Validation Loss: 0.747922956943512, Validation Accuracy: 0.762499988079071\n",
            "Epoch 50, Loss: 0.14316841959953308, Validation Loss: 0.6875897645950317, Validation Accuracy: 0.793749988079071\n",
            "Epoch 60, Loss: 0.05809243768453598, Validation Loss: 0.7078016996383667, Validation Accuracy: 0.8374999761581421\n",
            "Epoch 70, Loss: 0.024017715826630592, Validation Loss: 0.7799182534217834, Validation Accuracy: 0.8500000238418579\n",
            "Epoch 80, Loss: 0.013192825950682163, Validation Loss: 0.8462011218070984, Validation Accuracy: 0.8500000238418579\n",
            "Epoch 90, Loss: 0.008450605906546116, Validation Loss: 0.8970476388931274, Validation Accuracy: 0.856249988079071\n",
            "Epoch 100, Loss: 0.005923462100327015, Validation Loss: 0.9371633529663086, Validation Accuracy: 0.856249988079071\n",
            "Total training time: 207.07 seconds\n",
            "Accuracy on test set: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decreased Layers**"
      ],
      "metadata": {
        "id": "ZnPbnl5IYB3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJlUXyIDX2O3",
        "outputId": "a6c7cea9-ef90-4694-8541-3ab422276544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.1445320844650269, Validation Loss: 1.2199186086654663, Validation Accuracy: 0.5\n",
            "Epoch 20, Loss: 0.9495308995246887, Validation Loss: 1.0947479009628296, Validation Accuracy: 0.574999988079071\n",
            "Epoch 30, Loss: 0.8414937257766724, Validation Loss: 1.0481085777282715, Validation Accuracy: 0.5687500238418579\n",
            "Epoch 40, Loss: 0.7535229921340942, Validation Loss: 0.9766480326652527, Validation Accuracy: 0.612500011920929\n",
            "Epoch 50, Loss: 0.6643410921096802, Validation Loss: 0.9000328779220581, Validation Accuracy: 0.6625000238418579\n",
            "Epoch 60, Loss: 0.5798506140708923, Validation Loss: 0.8314506411552429, Validation Accuracy: 0.6937500238418579\n",
            "Epoch 70, Loss: 0.5056558847427368, Validation Loss: 0.7761356830596924, Validation Accuracy: 0.6875\n",
            "Epoch 80, Loss: 0.44126391410827637, Validation Loss: 0.7319610714912415, Validation Accuracy: 0.7124999761581421\n",
            "Epoch 90, Loss: 0.38463106751441956, Validation Loss: 0.6947047710418701, Validation Accuracy: 0.71875\n",
            "Epoch 100, Loss: 0.3344767391681671, Validation Loss: 0.6621838808059692, Validation Accuracy: 0.762499988079071\n",
            "Total training time: 34.67 seconds\n",
            "Accuracy on test set: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Increased Layers**"
      ],
      "metadata": {
        "id": "YTyfVSOeYGp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 1024\n",
        "num_layers = 3\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrQ9NjyCX-zH",
        "outputId": "dda1c86d-ea8a-4776-ab2f-1bddc054a5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.9415010809898376, Validation Loss: 1.1135923862457275, Validation Accuracy: 0.59375\n",
            "Epoch 20, Loss: 0.7023614048957825, Validation Loss: 1.0187636613845825, Validation Accuracy: 0.65625\n",
            "Epoch 30, Loss: 0.43792882561683655, Validation Loss: 0.9759095311164856, Validation Accuracy: 0.737500011920929\n",
            "Epoch 40, Loss: 0.16991902887821198, Validation Loss: 0.9250847697257996, Validation Accuracy: 0.7875000238418579\n",
            "Epoch 50, Loss: 0.20541562139987946, Validation Loss: 0.9805384874343872, Validation Accuracy: 0.8125\n",
            "Epoch 60, Loss: 0.022668074816465378, Validation Loss: 0.9746415019035339, Validation Accuracy: 0.8062499761581421\n",
            "Epoch 70, Loss: 0.008554743602871895, Validation Loss: 1.0326439142227173, Validation Accuracy: 0.824999988079071\n",
            "Epoch 80, Loss: 0.005073691718280315, Validation Loss: 1.0900180339813232, Validation Accuracy: 0.824999988079071\n",
            "Epoch 90, Loss: 0.003444534493610263, Validation Loss: 1.1319870948791504, Validation Accuracy: 0.824999988079071\n",
            "Epoch 100, Loss: 0.0025270571932196617, Validation Loss: 1.1652553081512451, Validation Accuracy: 0.824999988079071\n",
            "Total training time: 334.56 seconds\n",
            "Accuracy on test set: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Parameters Decreased Epochs**"
      ],
      "metadata": {
        "id": "FbS5ZMe4aNkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "cwYnRExOZ3at",
        "outputId": "0533376e-cdb6-4149-daca-fe6f91aa1cdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 1.042708158493042, Validation Loss: 1.0944465398788452, Validation Accuracy: 0.5874999761581421\n",
            "Epoch 20, Loss: 0.7810733914375305, Validation Loss: 1.0229591131210327, Validation Accuracy: 0.606249988079071\n",
            "Epoch 30, Loss: 0.6151356101036072, Validation Loss: 0.8977915048599243, Validation Accuracy: 0.6812499761581421\n",
            "Epoch 40, Loss: 0.45939743518829346, Validation Loss: 0.813704788684845, Validation Accuracy: 0.7562500238418579\n",
            "Epoch 50, Loss: 0.3059541583061218, Validation Loss: 0.7155240178108215, Validation Accuracy: 0.768750011920929\n",
            "Total training time: 49.42 seconds\n",
            "Accuracy on test set: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Parameters 150 Epochs**\n",
        "\n"
      ],
      "metadata": {
        "id": "4RiC6q51aS0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 150\n",
        "batch_size = 128\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "huzZtB-QaGrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c5bf2af-1ca7-4eb6-bf97-d18a3299ff96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.0352375507354736, Validation Loss: 1.0827133655548096, Validation Accuracy: 0.612500011920929\n",
            "Epoch 20, Loss: 0.7737231850624084, Validation Loss: 1.025247573852539, Validation Accuracy: 0.6000000238418579\n",
            "Epoch 30, Loss: 0.6120564341545105, Validation Loss: 0.9046235084533691, Validation Accuracy: 0.668749988079071\n",
            "Epoch 40, Loss: 0.452109158039093, Validation Loss: 0.8157098889350891, Validation Accuracy: 0.75\n",
            "Epoch 50, Loss: 0.2968067526817322, Validation Loss: 0.7215312123298645, Validation Accuracy: 0.762499988079071\n",
            "Epoch 60, Loss: 0.1757899969816208, Validation Loss: 0.6640605926513672, Validation Accuracy: 0.7749999761581421\n",
            "Epoch 70, Loss: 0.10002313554286957, Validation Loss: 0.6638315320014954, Validation Accuracy: 0.800000011920929\n",
            "Epoch 80, Loss: 0.05418555811047554, Validation Loss: 0.6979402303695679, Validation Accuracy: 0.8187500238418579\n",
            "Epoch 90, Loss: 0.030572952702641487, Validation Loss: 0.7427447438240051, Validation Accuracy: 0.8187500238418579\n",
            "Epoch 100, Loss: 0.019474342465400696, Validation Loss: 0.785469651222229, Validation Accuracy: 0.8187500238418579\n",
            "Epoch 110, Loss: 0.01354053895920515, Validation Loss: 0.8226608037948608, Validation Accuracy: 0.8187500238418579\n",
            "Epoch 120, Loss: 0.009992429986596107, Validation Loss: 0.8545113801956177, Validation Accuracy: 0.831250011920929\n",
            "Epoch 130, Loss: 0.007696565240621567, Validation Loss: 0.8820725679397583, Validation Accuracy: 0.8374999761581421\n",
            "Epoch 140, Loss: 0.006122001446783543, Validation Loss: 0.9062856435775757, Validation Accuracy: 0.831250011920929\n",
            "Epoch 150, Loss: 0.004992879927158356, Validation Loss: 0.9278146624565125, Validation Accuracy: 0.831250011920929\n",
            "Total training time: 95.89 seconds\n",
            "Accuracy on test set: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Model**"
      ],
      "metadata": {
        "id": "LFREsbnXcir1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i + batch_size]\n",
        "        targets = y_train[i:i + batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Validation every 10 epochs\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)  # Assuming X_val is also properly reshaped\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_accuracy = (predicted == y_val).float().mean()\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy.item()}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_val).sum().item() / y_val.size(0)\n",
        "    print(f'Accuracy on test set: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "b4ir8D3OcQ3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1734677-dbf3-4853-8b18-0d92811a9354"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.038161039352417, Validation Loss: 1.0897902250289917, Validation Accuracy: 0.612500011920929\n",
            "Epoch 20, Loss: 0.7728594541549683, Validation Loss: 1.0152944326400757, Validation Accuracy: 0.6187499761581421\n",
            "Epoch 30, Loss: 0.6064001321792603, Validation Loss: 0.8901888132095337, Validation Accuracy: 0.668749988079071\n",
            "Epoch 40, Loss: 0.44344985485076904, Validation Loss: 0.8026259541511536, Validation Accuracy: 0.75\n",
            "Epoch 50, Loss: 0.28642165660858154, Validation Loss: 0.7018927335739136, Validation Accuracy: 0.768750011920929\n",
            "Epoch 60, Loss: 0.16985616087913513, Validation Loss: 0.6425787210464478, Validation Accuracy: 0.800000011920929\n",
            "Epoch 70, Loss: 0.09500674158334732, Validation Loss: 0.6399987936019897, Validation Accuracy: 0.8062499761581421\n",
            "Epoch 80, Loss: 0.04968228563666344, Validation Loss: 0.6734193563461304, Validation Accuracy: 0.824999988079071\n",
            "Epoch 90, Loss: 0.0280934926122427, Validation Loss: 0.7189597487449646, Validation Accuracy: 0.831250011920929\n",
            "Epoch 100, Loss: 0.01802944205701351, Validation Loss: 0.7622336149215698, Validation Accuracy: 0.84375\n",
            "Total training time: 63.64 seconds\n",
            "Accuracy on test set: 0.84\n"
          ]
        }
      ]
    }
  ]
}